# AmFi - Sistema de Monitoramento de Portf√≥lio

> **IMPORTANTE**: Sempre utilizar Claude Sonnet 4.0 para trabalhar neste projeto.

## Contexto do Projeto
Sistema de monitoramento automatizado para fundos de investimento estruturados no Brasil. Processa escrituras de deb√™ntures (PDFs) em configura√ß√µes JSON para executar monitoramento de compliance, an√°lise de fluxo de caixa e verifica√ß√£o de liquidez.

## Arquitetura do Sistema

### Fluxo de Dados Principal
```
Escritura (PDF) ‚Üí JSON Config ‚Üí Monitoramento Python ‚Üí JSON Resultados ‚Üí Dashboard
     ‚Üì               ‚Üì                    ‚Üì                    ‚Üì
  Manual         Autom√°tico         5 Componentes        Consolidado
```

### Componentes Principais
1. **Monitoramento Individual**: Verifica compliance por pool
2. **Dashboard de Exce√ß√µes**: Consolida apenas viola√ß√µes
3. **An√°lise Comparativa**: Evolu√ß√£o temporal dia-a-dia
4. **Fluxo de Caixa**: Proje√ß√£o de receb√≠veis (adimplentes/inadimplentes)
5. **An√°lise de Liquidez**: Cobertura de amortiza√ß√µes futuras

## Estrutura de Diret√≥rios
```
/mnt/c/amfi/
‚îú‚îÄ‚îÄ docs/                    # Documenta√ß√£o do projeto
‚îÇ   ‚îú‚îÄ‚îÄ processos/           # Checklists e processos operacionais
‚îÇ   ‚îú‚îÄ‚îÄ sessions/            # APENAS to-dos por data (sem documenta√ß√£o t√©cnica)
‚îÇ   ‚îî‚îÄ‚îÄ technical/           # Documenta√ß√£o t√©cnica detalhada
‚îú‚îÄ‚îÄ tests/                   # Testes organizados
‚îÇ   ‚îú‚îÄ‚îÄ unit/               # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ integration/        # Testes de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ performance/        # Testes de performance
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/           # Dados de teste
‚îú‚îÄ‚îÄ scripts/                # Scripts utilit√°rios e debug
‚îú‚îÄ‚îÄ monitor/                # Sistema de monitoramento
‚îÇ   ‚îú‚îÄ‚îÄ base/               # Monitores padr√£o
‚îÇ   ‚îú‚îÄ‚îÄ custom/             # Monitores espec√≠ficos
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Utilit√°rios compartilhados
‚îú‚îÄ‚îÄ udfs/                   # C√≥digo Python principal (UDFs Excel)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ csv/                # Dados di√°rios dos pools (PL, SR, JR)
‚îÇ   ‚îú‚îÄ‚îÄ xlsx/               # Carteiras detalhadas (receb√≠veis)
‚îÇ   ‚îú‚îÄ‚îÄ escrituras/         # JSONs de configura√ß√£o dos pools
‚îÇ   ‚îú‚îÄ‚îÄ escrituras_md/      # Escrituras originais em markdown
‚îÇ   ‚îî‚îÄ‚îÄ templates/          # Templates para cria√ß√£o de novos JSONs
‚îî‚îÄ‚îÄ Monitoramento.xlsm      # Interface Excel
```

## Estado Atual da Implementa√ß√£o

### ‚úÖ Conclu√≠do
- Estrutura base de UDFs Excel
- Handlers para CSV/XLSX/JSON
- Sistema de cache
- Fun√ß√µes de c√°lculo financeiro (IS, JR)
- **7 pools auditados e padronizados** em JSON v2.2
- **JSON otimizado para monitoramento** (template v2.2 organizado em 5 se√ß√µes)
- **Estrutura flex√≠vel de concentra√ß√£o** (top_N gen√©rico)
- **Consolida√ß√£o de limites** dispersos em `limites_monitoramento`
- **Mapeamento de eventos de monitoramento** organizados por categoria (7 base + customizados)
- **Auditoria sistem√°tica completa**: 100% de dados verificados contra escrituras originais
- **Padroniza√ß√£o de formatos**: Percentuais em decimal, cronogramas corrigidos
- **Template como fonte √∫nica de verdade**: Reorganizado em 5 se√ß√µes l√≥gicas

### üîÑ Em Desenvolvimento
- **Sistema de monitoramento modular** (5 arquivos por natureza)
- **Monitores customizados espec√≠ficos** (20+ identificados)
- Dashboard de exce√ß√µes
- An√°lise de fluxo de caixa
- Sistema de descoberta autom√°tica de pools (data_loader funcional)

### üìã Mapeamento Real de Eventos de Monitoramento

#### **üèóÔ∏è Eventos Base (7 principais - Template v2.2)**
Padronizados e implementados em todos os pools via `monitoramentos_ativos`:

**1. SUBORDINA√á√ÉO (2 eventos base)**
- `subordinacao` - √çndice m√≠nimo de subordina√ß√£o ‚úÖ **IMPLEMENTADO**
- `subordinacao_critica` - Limite cr√≠tico de subordina√ß√£o ‚úÖ **IMPLEMENTADO**

**2. CONCENTRA√á√ÉO (2 eventos base)**
- `concentracao_sacados` - Concentra√ß√£o m√°xima por sacado individual
- `concentracao_cedentes` - Concentra√ß√£o m√°xima por cedente individual

**3. INADIMPL√äNCIA (2 eventos base)**
- `inadimplencia_30_dias` - Inadimpl√™ncia 30+ dias (limite: 3-4%)
- `inadimplencia_90_dias` - Inadimpl√™ncia 90+ dias (limite: 2%)

**4. ELEGIBILIDADE (1 evento base)**
- `elegibilidade_geral` - Crit√©rios gerais de elegibilidade de ativos

#### **‚öôÔ∏è Eventos Customizados por Pool (20+ identificados)**
Espec√≠ficos por caracter√≠sticas de cada pool:

**üîß SUPERSIM POOL #1 (Custom)**
- `recovery_rate_mensal` - Taxa de recupera√ß√£o m√≠nima 95%
- `concentracao_socinal` - Limite espec√≠fico SOCINAL
- `concentracao_bmp` - Limite espec√≠fico BMP

**üîß UPVENDAS POOL #2 (Custom)**
- `substituicao_pix_parcelado` - Substitui√ß√£o PIX ‚Üí URs
- `despesas_adicionais_maximas` - Limite despesas extras

**üîß AFA POOL #1 (Custom)**
- `sacados_especificos_bmp` - Limites diferenciados BMP
- `sacados_especificos_socinal` - Limites diferenciados SOCINAL

**üîß COMUM A M√öLTIPLOS POOLS (Legacy)**
- `vencimento_medio_carteira` - Prazo m√©dio ponderado (80-90 dias)
- `valor_minimo_direito_creditorio` - Valor m√≠nimo por ativo (R$ 100-1.000)
- `valor_individual_maximo` - Valor m√°ximo por ativo (R$ 300k-500k)
- `taxa_minima_financiamento` - Taxa m√≠nima (150% CDI)
- `periodo_formacao_carteira` - Per√≠odo inicial (30-90 dias)
- `prazo_limite_aquisicoes` - Prazo para aquisi√ß√µes (11-36 meses)
- `provisoes_pdd` - Provis√µes grupos AA-H
- `fundos_reserva` - Reservas obrigat√≥rias
- `concentracao_top_10_sacados` - Top 10 sacados
- `concentracao_top_10_cedentes` - Top 10 cedentes
- `vencimento_individual_minimo` - Vencimento m√≠nimo (3-15 dias)
- `vencimento_individual_maximo` - Vencimento m√°ximo (45-360 dias)

#### **üìä Estat√≠sticas Reais**
- **Eventos base padronizados**: 7 (template v2.2)
- **Eventos customizados identificados**: 20+ (JSONs legacy)
- **Total de combina√ß√µes √∫nicas**: 25+ eventos distintos
- **Pools com eventos customizados**: 100% (todos t√™m particularidades)
- An√°lise de liquidez vs amortiza√ß√µes
- Comparativo temporal autom√°tico
- Sistema de alertas
- Testes automatizados

## Problemas T√©cnicos Resolvidos

### ‚úÖ 1. Inconsist√™ncia de Nomenclatura (RESOLVIDO - 2025-07-11)
**Problema**: Dados CSV/XLSX usavam `LeCapital Pool #1`, mas JSONs eram `lecapital_pool_1_monitoring.json`
**Impacto**: Sistema precisava de mapeamentos manuais, falhas de matching autom√°tico
**Solu√ß√£o**: Padroniza√ß√£o total para formato dos dados de produ√ß√£o
**Resultado**: 7/7 pools com matching autom√°tico 100% funcional

**Arquivos Renomeados**:
- `lecapital_pool_1_monitoring.json` ‚Üí `LeCapital Pool #1.json`
- `afa_pool_1_monitoring.json` ‚Üí `AFA Pool #1.json`
- `credmei_pool_1_monitoring.json` ‚Üí `Credmei Pool #1.json`
- `supersim_pool_1_monitoring.json` ‚Üí `SuperSim Pool #1.json`
- `a55_pool_cartao_2_monitoring.json` ‚Üí `a55 Pool #2.json`
- `formento_pool_3_monitoring.json` ‚Üí `Formento Pool #3.json`
- `upvendas_pool_2_monitoring.json` ‚Üí `Up Vendas Pool #2.json`

**Benef√≠cios Alcan√ßados**:
- ‚úÖ Eliminou mapeamentos manuais hardcoded
- ‚úÖ Sistema de descoberta autom√°tica funcional  
- ‚úÖ Compatibilidade total CSV ‚Üî JSON ‚Üî XLSX
- ‚úÖ Facilita debug e manuten√ß√£o
- ‚úÖ Escalabilidade para novos pools

## Problemas T√©cnicos a Resolver

### 1. Gest√£o de Particularidades (20% Customizado)
**Problema**: Cada escritura tem regras espec√≠ficas al√©m do padr√£o comum.
**Solu√ß√£o Proposta**: Sistema de plugins de monitoramento
```python
# monitors/base/ - Monitores padr√£o (80%)
# monitors/custom/pool_name/ - Monitores espec√≠ficos (20%)
```

### 2. Performance com Arquivos Grandes
**Problema**: XLSX di√°rios podem ter >100MB e >50k linhas.
**Solu√ß√µes**:
- Processamento incremental (delta apenas)
- Leitura seletiva de colunas
- Cache com TTL inteligente
- Processamento paralelo por pool

### 3. Versionamento e Auditoria
**Problema**: Compliance exige hist√≥rico completo de mudan√ßas.
**Solu√ß√£o**: Adicionar metadados em cada execu√ß√£o
```json
{
  "execution_id": "uuid",
  "timestamp": "ISO-8601",
  "data_sources": {"csv": "hash", "xlsx": "hash"},
  "changes_detected": []
}
```

### 4. Limites Din√¢micos por Per√≠odo
**Problema**: Alguns limites mudam (ex: forma√ß√£o vs opera√ß√£o).
**Solu√ß√£o**: Configura√ß√£o temporal de limites
```json
"limites": [
  {"vigencia": "2025-03-18/2025-05-17", "valor": 0.50},
  {"vigencia": "2025-05-18/null", "valor": 0.35}
]
```

### 5. Parsing de PDFs de Escrituras
**Problema**: Extrair dados estruturados de documentos legais.
**Desafios**:
- Varia√ß√£o de formato entre escrituras
- Termos legais em portugu√™s jur√≠dico
- Tabelas e anexos complexos
- Aditamentos que modificam termos

## Padr√µes de C√≥digo

### Nomenclatura
- Fun√ß√µes: `snake_case`
- Classes: `PascalCase`
- Constantes: `UPPER_SNAKE_CASE`
- Arquivos: `snake_case.py`

### Estrutura de Monitores
```python
class MonitorBase:
    def validar_dados(self, df): pass
    def calcular(self, df, config): pass
    def gerar_resultado(self, valor, limite): pass
```

### Tratamento de Erros
- Valida√ß√£o de entrada em todas as fun√ß√µes
- Mensagens claras em portugu√™s
- Fallback para valores seguros
- Log detalhado para debug

## Princ√≠pios de Desenvolvimento e Arquitetura

### üéØ Mentalidade de Desenvolvimento S√™nior
- **SEMPRE pensar como dev senior e arquiteto de solu√ß√µes**
- **NUNCA ser agreeable se houver propostas melhores**
- **Questionar decis√µes t√©cnicas** e propor alternativas superiores
- **Priorizar qualidade de c√≥digo** sobre velocidade de entrega
- **Focar em performance** desde o design inicial
- **Cobrir pontos cegos** atrav√©s de an√°lise cr√≠tica e revis√£o sistem√°tica

### üèóÔ∏è Princ√≠pios Arquiteturais SOLID
- **Single Responsibility**: Cada classe/fun√ß√£o tem UMA responsabilidade
- **Open/Closed**: Extens√≠vel via novos componentes, fechado para modifica√ß√£o
- **Liskov Substitution**: Interfaces consistentes e substitu√≠veis
- **Interface Segregation**: Interfaces espec√≠ficas por necessidade
- **Dependency Inversion**: Depend√™ncias em abstra√ß√µes, n√£o implementa√ß√µes

### ‚ö° Foco em Performance
- **Processamento paralelo** quando poss√≠vel (pools independentes)
- **Cache inteligente** com TTL adequado
- **Leitura seletiva** de colunas em DataFrames grandes
- **Lazy loading** de configura√ß√µes e dados
- **Profiling regular** para identificar gargalos

### üö´ Anti-patterns Proibidos
- **God Classes** (como data_loader.py atual - deve ser refatorado)
- **Business logic em utilit√°rios** (separar responsabilidades)
- **Tight coupling** entre m√≥dulos (usar inje√ß√£o de depend√™ncia)
- **Fun√ß√µes com >20 linhas** (quebrar em fun√ß√µes menores)
- **Responsabilidades misturadas** (um arquivo = uma responsabilidade)

### üîç Cobertura de Pontos Cegos
- **Code review rigoroso** questionando cada decis√£o
- **An√°lise de edge cases** antes da implementa√ß√£o
- **Testes de carga** com datasets grandes (>50k registros)
- **Valida√ß√£o de mem√≥ria** para opera√ß√µes com DataFrames
- **Disaster recovery** e fallbacks para falhas de sistema

### üìè M√©tricas de Qualidade T√©cnica
- **Cobertura de testes** > 80%
- **Complexidade ciclom√°tica** < 10 por fun√ß√£o
- **Duplica√ß√£o de c√≥digo** < 5%
- **Tempo de execu√ß√£o** < 30s para processamento completo
- **Uso de mem√≥ria** < 2GB para datasets padr√£o

## Arquitetura de Monitoramento

### Estrutura Hier√°rquica:
```
/mnt/c/amfi/
‚îú‚îÄ‚îÄ monitor/
‚îÇ   ‚îú‚îÄ‚îÄ base/                          # Monitores padr√£o (7 eventos base)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor_subordinacao.py    # 2 eventos ‚úÖ IMPLEMENTADO
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor_concentracao.py    # 2 eventos base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor_inadimplencia.py   # 2 eventos ‚úÖ PRONTO (aguarda integra√ß√£o)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor_elegibilidade.py   # 1 evento base
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitor_operacional.py     # Eventos legacy/customizados
‚îÇ   ‚îú‚îÄ‚îÄ custom/                        # Monitores espec√≠ficos por pool
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supersim_pool_1_recovery_rate.py    # üîß Taxa de recupera√ß√£o SuperSim
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ afa_pool_1_sacados_especificos.py   # üîß Limites especiais BMP, SOCINAL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upvendas_pool_2_substituicao_pix.py # üîß Substitui√ß√£o PIX‚ÜíURs UpVendas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {pool_id}_{funcionalidade}.py       # Padr√£o de nomenclatura
‚îÇ   ‚îú‚îÄ‚îÄ utils/                         # Utilit√°rios compartilhados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py             # ‚úÖ Carregamento principal (9 etapas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_loaders.py            # ‚úÖ Carregamento CSV/XLSX
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_handler.py            # ‚úÖ Valida√ß√µes e metadados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts.py                  # ‚úÖ Sistema de alertas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_discovery.py          # ‚úÖ Descoberta de arquivos
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py                # ‚úÖ Orquestra√ß√£o de monitores (parcial)
‚îÇ   ‚îî‚îÄ‚îÄ [arquivos legacy removidos]    # pool_discovery, monitoring_engine, etc.
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ config/                        # üìÅ Configura√ß√µes do sistema
    ‚îÇ   ‚îú‚îÄ‚îÄ ignore_pools.json          # Pools ignorados
    ‚îÇ   ‚îî‚îÄ‚îÄ test_pools.json            # Cen√°rios de teste
    ‚îú‚îÄ‚îÄ csv/                           # Dados gerais dos pools
    ‚îú‚îÄ‚îÄ xlsx/                          # Dados detalhadas das carteiras
    ‚îú‚îÄ‚îÄ escrituras/                    # Configura√ß√µes espec√≠ficas por pool
    ‚îÇ   ‚îî‚îÄ‚îÄ legacy/                    # JSONs no formato antigo (arquivados)
    ‚îî‚îÄ‚îÄ templates/                     # Templates para novos pools
        ‚îî‚îÄ‚îÄ pool_monitoring_template.json
```

### Estado dos Arquivos Principais (√öltima Verifica√ß√£o: 2025-07-13)

#### **Estrutura de Dados Real (Vari√°vel Diariamente)**
- **CSV Dashboard**: ~45 registros de pools, colunas `nome/sr/jr/pl`
- **XLSX Portfolio**: ~79k registros de receb√≠veis, 36+ pools, coluna identificadora `pool`
- **Enriquecimento**: Processo tempor√°rio durante execu√ß√£o (+2 colunas calculadas)

#### **Arquivos Funcionais Confirmados**
| Arquivo | Status | Interface | √öltima Verifica√ß√£o |
|---------|--------|-----------|-------------------|
| **data_loader.py** | ‚úÖ FUNCIONAL | `load_pool_data()` | 2025-07-13 (79k registros em 10s) |
| **orchestrator.py** | ‚úÖ FUNCIONAL | `run_monitoring()` | 2025-07-13 (100% taxa sucesso) |
| **monitor_subordinacao.py** | ‚úÖ FUNCIONAL | `run_subordination_monitoring()` | 2025-07-13 (integrado) |
| **monitor_inadimplencia.py** | ‚úÖ FUNCIONAL | `run_delinquency_monitoring()` | 2025-07-13 (c/ enriquecimento) |

### Fluxo de Execu√ß√£o Integrado (Testado e Funcionando):

```
orchestrator.run_monitoring(pool_name=None)
    ‚Üì
data_loader.load_pool_data() [CENTRALIZADOR]
    ‚îú‚îÄ‚îÄ Carrega CSV (~45 pools) + XLSX (~79k registros) + JSONs
    ‚îú‚îÄ‚îÄ Modo DEBUG: test_pools.json ‚Üí ['AFA Pool #1', 'LeCapital Pool #1']
    ‚îú‚îÄ‚îÄ Modo NORMAL: descoberta autom√°tica + ignore_pools.json
    ‚îî‚îÄ‚îÄ Retorna: DataFrame XLSX com 16 colunas originais
    ‚Üì
Para cada pool configurado:
    ‚îú‚îÄ‚îÄ _has_subordination_monitoring(config) ? ‚Üí run_subordination_monitoring()
    ‚îú‚îÄ‚îÄ _has_delinquency_monitoring(config) ? ‚Üí run_delinquency_monitoring()
    ‚îÇ   ‚îú‚îÄ‚îÄ 1¬∫ pool: ENRIQUECE XLSX globalmente (16‚Üí18 colunas)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ +dias_atraso: calculado para todos os 79k registros
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ +grupo_de_risco: classifica√ß√£o AA-H para todos
    ‚îÇ   ‚îî‚îÄ‚îÄ 2¬∫ pool: REUTILIZA campos j√° calculados (performance)
    ‚îî‚îÄ‚îÄ [futuros monitores: usam XLSX j√° enriquecido]
    ‚Üì
Resultado: DataFrame na mem√≥ria com 18 colunas (tempor√°rio)
Pr√≥xima execu√ß√£o: reinicia com 16 colunas originais
```

#### **Processo de Enriquecimento Progressivo (N√£o Permanente)**
‚ö†Ô∏è **IMPORTANTE**: Enriquecimento acontece DURANTE a execu√ß√£o, n√£o √© estado permanente.

**Estados do XLSX**:
- **Inicial**: 16 colunas (dados do arquivo)
- **Durante execu√ß√£o**: 18 colunas (16 + dias_atraso + grupo_de_risco)
- **Fim da execu√ß√£o**: DataFrame enriquecido existe apenas na mem√≥ria
- **Pr√≥xima execu√ß√£o**: Volta ao estado inicial (16 colunas)

### Sistema de Carregamento Refinado:
- **Fluxo de 9 etapas**: CSV ‚Üí XLSX ‚Üí Valida√ß√µes ‚Üí Pools ‚Üí Ignore List ‚Üí Filtros ‚Üí JSON ‚Üí Filtro XLSX ‚Üí Valida√ß√µes Pool
- **Sistema de filtros**: Executa todos os pools, pools espec√≠ficos ou cen√°rios de teste
- **Ignore list**: Pools exclu√≠dos automaticamente do monitoramento
- **Log detalhado**: Registro completo de todas as opera√ß√µes
- **Sem hardcode**: Descobre pools automaticamente via arquivos existentes
- **Configura√ß√£o flex√≠vel**: JSON por pool com limites espec√≠ficos
- **Customiza√ß√µes**: Pools podem ter monitores √∫nicos al√©m dos padr√£o

### Estrat√©gia de Enriquecimento Progressivo de Dados

#### **Conceito Central**
- **DataFrame XLSX** √© passado por refer√™ncia entre monitores
- **Cada monitor** pode adicionar colunas calculadas
- **Dados enriquecidos** ficam dispon√≠veis para monitores posteriores
- **Evita rec√°lculos** desnecess√°rios e melhora performance

#### **Campos Adicionados por Monitor**
```
Data Original (XLSX):
‚îú‚îÄ‚îÄ status, vencimento_original, valor_presente, sacado, cedente...

Monitor de Inadimpl√™ncia adiciona:
‚îú‚îÄ‚îÄ dias_atraso: int (calculado vs data atual)
‚îú‚îÄ‚îÄ grupo_de_risco: str (AA, A, B, C, D, E, F, G, H)
‚îî‚îÄ‚îÄ [PDD fields ficam para v2.0]

Futuros Monitores podem usar:
‚îú‚îÄ‚îÄ Concentra√ß√£o: usar grupo_de_risco para an√°lise
‚îú‚îÄ‚îÄ Elegibilidade: usar dias_atraso para filtros
‚îî‚îÄ‚îÄ Customizados: usar qualquer campo calculado
```

#### **Vantagens da Abordagem**
- ‚úÖ **Performance**: C√°lculos feitos uma vez, usados sempre
- ‚úÖ **Consist√™ncia**: √önica fonte de verdade para cada c√°lculo  
- ‚úÖ **Extensibilidade**: Novos monitores reutilizam campos existentes
- ‚úÖ **Auditoria**: Dados enriquecidos persistem na mem√≥ria

### Fun√ß√µes Padr√£o por Monitor:

#### **Monitores Base (Padr√£o 7 eventos)**
- `_find_{monitor_name}_monitor(s)(config)` - Buscar configura√ß√£o no JSON
- `_has_{monitor_name}_monitoring(config)` - Verificar se monitor est√° ativo
- `validate_data(df, config)` - Verifica√ß√£o de entrada
- `calculate_{monitor_name}(df, config)` - C√°lculo principal  
- `run_{monitor_name}_monitoring(df, config)` - Interface para orquestrador
- **Exemplos**: 
  - `monitor_subordinacao.py` ‚úÖ implementado
  - `monitor_inadimplencia.py` ‚úÖ pronto (aguarda integra√ß√£o)

#### **Monitores Customizados (20+ eventos espec√≠ficos)**
- Implementa√ß√£o espec√≠fica por pool conforme necessidade
- Nomenclatura: `{pool_id}_{funcionalidade}.py`
- **üîß Custom** - Indica monitor espec√≠fico de pool
- **Exemplos**: 
  - `supersim_pool_1_recovery_rate.py` 
  - `afa_pool_1_sacados_especificos.py`
  - `upvendas_pool_2_substituicao_pix.py`

## Integra√ß√£o com Orquestrador

### Nova Arquitetura Integrada - data_loader como Centralizador

#### **Interface Principal Unificada:**

```python
from monitor.orchestrator import run_monitoring

# Processar todos os pools (modo normal ou debug)
resultado = run_monitoring()

# Processar pool espec√≠fico
resultado = run_monitoring("LeCapital Pool #1")
```

#### **Fluxo Interno do Orquestrador:**

```python
def run_monitoring(pool_name: str = None) -> Dict:
    # 1. data_loader centraliza tudo (descoberta + configura√ß√£o + carregamento)
    dados = data_loader.load_pool_data()
    
    # 2. Filtrar por pool espec√≠fico se solicitado
    pools_para_processar = [pool_name] if pool_name else dados["pools_processados"]
    
    # 3. Para cada pool configurado:
    for pool in pools_para_processar:
        config = dados["pools_configs"][pool]
        pool_csv = filter_csv_by_pool(dados["csv_data"], pool)
        
        # 4. Execu√ß√£o condicional baseada no JSON de configura√ß√£o
        if _has_subordination_monitoring(config):
            resultado_sub = run_subordination_monitoring(pool_csv, config)
            
        if _has_delinquency_monitoring(config):
            # ENRIQUECE o DataFrame XLSX com novos campos
            dados["xlsx_data"] = run_delinquency_monitoring(
                pool_csv, dados["xlsx_data"], config
            )
            
        # Futuros monitores usar√£o dados j√° enriquecidos
```

### Monitor de Subordina√ß√£o - Interface Atual

O monitor de subordina√ß√£o est√° **100% funcional** e integrado ao orquestrador.

#### **Execu√ß√£o Condicional:**
```python
def _has_subordination_monitoring(config: Dict) -> bool:
    """Verifica se monitor de subordina√ß√£o est√° ativo no JSON"""
    try:
        monitor = _find_subordination_monitor(config)
        return monitor is not None and monitor.get('ativo', False)
    except ValueError:
        return False
```

### Monitor de Inadimpl√™ncia - Enriquecimento de Dados

O monitor de inadimpl√™ncia est√° **funcionalmente completo** e pronto para integra√ß√£o.

#### **Estrat√©gia de Enriquecimento:**
```python
def _has_delinquency_monitoring(config: Dict) -> bool:
    """Verifica se monitores de inadimpl√™ncia est√£o ativos no JSON"""
    try:
        monitors = _find_delinquency_monitors(config)  # Fun√ß√£o j√° existe
        return len(monitors) > 0
    except ValueError:
        return False

def run_delinquency_monitoring(csv_df, xlsx_df, config) -> pd.DataFrame:
    """
    Interface para orquestrador - ENRIQUECE DataFrame XLSX
    
    Args:
        csv_df: Dados do pool (PL, SR, JR)
        xlsx_df: Carteira detalhada (ser√° enriquecida)
        config: Configura√ß√£o JSON do pool
        
    Returns:
        DataFrame XLSX enriquecido com campos adicionais
    """
    # 1. Calcular campos de enriquecimento
    xlsx_enriched = calculate_days_overdue(xlsx_df)  # Adiciona 'dias_atraso'
    
    # 2. Classificar grupos de risco baseado em PDD config
    pdd_grupos = _find_pdd_config(config)
    xlsx_enriched['grupo_de_risco'] = classify_risk_groups(
        xlsx_enriched['dias_atraso'], pdd_grupos
    )
    
    # 3. Executar monitoramento de inadimpl√™ncia
    resultado_monitoring = calculate_delinquency_analysis(
        xlsx_enriched, csv_df, config
    )
    
    # 4. Retornar DataFrame enriquecido + resultado
    return xlsx_enriched, resultado_monitoring
```

#### **Campos Adicionados ao DataFrame:**
- **`dias_atraso`**: Dias de atraso calculados vs `vencimento_original`
- **`grupo_de_risco`**: Classifica√ß√£o AA-H baseada na configura√ß√£o PDD
- **[PDD fields]**: Ficam para implementa√ß√£o v2.0

#### **Contrato de Dados:**

**Input:**
- `df`: DataFrame com colunas obrigat√≥rias: `sr`, `jr`, `pl` (min√∫sculas, valores num√©ricos)
- `config`: JSON com estrutura `monitoramentos_ativos` contendo monitor `id="subordinacao"`

**Output de Sucesso:**
```json
{
  "sucesso": true,
  "monitor": "subordination_ratio",
  "subordination_ratio": 0.2518,
  "subordination_ratio_percent": 25.18,
  "limite_minimo": 0.25,
  "limite_critico": 0.20,
  "status_limite_minimo": "enquadrado",
  "status_limite_critico": "enquadrado",
  "aporte_necessario": {
    "para_limite_minimo": 0.0,
    "para_limite_critico": 0.0
  },
  "dados_financeiros": {
    "pl_atual": 8761240.59,
    "sr_atual": 6555273.93,
    "jr_atual": 2205966.66,
    "denominador_calculo": 8761240.59
  }
}
```

**Output de Erro:**
```json
{
  "sucesso": false,
  "monitor": "subordination_ratio",
  "erro": "Falha na valida√ß√£o de dados"
}
```

#### **Separa√ß√£o de Responsabilidades:**

| Componente | Responsabilidade |
|------------|------------------|
| **Monitor** | ‚Ä¢ Validar estrutura de dados<br>‚Ä¢ Calcular subordination ratio<br>‚Ä¢ Verificar limites<br>‚Ä¢ Calcular aportes necess√°rios |
| **Orquestrador** | ‚Ä¢ Carregar dados (CSV/JSON)<br>‚Ä¢ Chamar monitor<br>‚Ä¢ Logar resultados<br>‚Ä¢ Enviar alertas<br>‚Ä¢ Persistir resultados |

#### **Estrat√©gia de Tratamento de Erros:**

**Categoriza√ß√£o por Severidade:**

**üî• CR√çTICOS (Parar execu√ß√£o completa):**
- Data source indispon√≠vel (CSV n√£o encontrado)
- Sistema de logging falhando  
- Configura√ß√£o global corrompida
- **A√ß√£o**: `return {"sucesso": false, "erro_critico": true}`

**‚ö†Ô∏è ALTOS (Log detalhado + Continue pr√≥ximo pool):**
- Pool sem JSON de configura√ß√£o
- Dados malformados em pool espec√≠fico
- C√°lculo com divis√£o por zero
- **A√ß√£o**: Log erro + marcar pool como "erro" + continuar

**üí° BAIXOS (Log simples + Continue):**
- Campos opcionais ausentes
- Valores fora do range esperado
- Timeouts tempor√°rios
- **A√ß√£o**: Log warning + continuar processamento

**Implementa√ß√£o no Orquestrador:**
1. **Dados Inv√°lidos**: Monitor retorna `{"sucesso": false, "erro": "Falha na valida√ß√£o"}` ‚Üí Continue pr√≥ximo pool
2. **C√°lculo com Erro**: Monitor retorna `{"sucesso": false, "erro": "Denominador zero"}` ‚Üí Continue pr√≥ximo pool  
3. **JSON Malformado**: Monitor retorna `{"sucesso": false, "erro": "Monitor n√£o encontrado"}` ‚Üí Continue pr√≥ximo pool
4. **CSV Indispon√≠vel**: Orquestrador retorna `{"sucesso": false, "erro_critico": true}` ‚Üí Parar tudo
5. **Sistema de Retry**: 3 tentativas com backoff exponencial para erros tempor√°rios

#### **Exemplo de Integra√ß√£o Completa:**

```python
# monitoring_engine.py
def executar_monitoramento_diario():
    pools = descobrir_pools_ativos()
    
    for pool_name in pools:
        try:
            # Subordina√ß√£o
            resultado_sub = orchestrate_subordination_monitoring(pool_name)
            
            # Concentra√ß√£o  
            resultado_conc = orchestrate_concentration_monitoring(pool_name)
            
            # Inadimpl√™ncia
            resultado_inad = orchestrate_default_monitoring(pool_name)
            
            # Consolidar resultados
            relatorio_pool = {
                "pool": pool_name,
                "data": datetime.now().isoformat(),
                "subordinacao": resultado_sub,
                "concentracao": resultado_conc,
                "inadimplencia": resultado_inad
            }
            
            gerar_relatorio_pool(relatorio_pool)
            
        except Exception as e:
            log_alerta({
                "tipo": "erro_critico",
                "pool": pool_name,
                "erro": str(e)
            })
```

#### **Status de Implementa√ß√£o:**

- ‚úÖ **monitor_subordinacao.py**: 100% funcional e testado
- ‚úÖ **Testes unit√°rios**: 100% aprovados (4 testes por pool)
- ‚úÖ **Documenta√ß√£o**: Interface e contratos definidos
- ‚úÖ **Orquestrador**: 100% implementado e funcional
- ‚úÖ **Estrat√©gia de erros**: Definida e documentada
- ‚ùå **Classes de erro espec√≠ficas**: Aguardando implementa√ß√£o
- ‚ùå **Sistema de retry**: Aguardando implementa√ß√£o
- ‚ùå **monitoring_engine.py**: Aguardando implementa√ß√£o

## Tracking de Implementa√ß√£o

### ‚úÖ Conclu√≠do
- [x] 5 arquivos base criados com fun√ß√µes documentadas
- [x] Estrutura flex√≠vel de concentra√ß√£o (top_N gen√©rico)
- [x] JSON otimizado para monitoramento (padr√£o definido)
- [x] Consolida√ß√£o de limites em `limites_monitoramento`
- [x] Documenta√ß√£o atualizada com arquitetura
- [x] **Estrutura reorganizada**: Monitores movidos para `/base/` e `/custom/` criado
- [x] **Sistema de utilit√°rios**: 5 arquivos em `/utils/` com esqueletos completos
- [x] **Fluxo de carregamento refinado**: Definido fluxo completo com 9 etapas
- [x] **Sistema de ignore list**: Estrutura para pools ignorados e testes
- [x] **Arquitetura de filtros**: Sistema flex√≠vel para executar pools espec√≠ficos
- [x] **Pasta data/config/**: Criada com ignore_pools.json e test_pools.json
- [x] **data_loader.py**: ‚úÖ COMPLETO - Implementado com fluxo de 9 etapas, todas fun√ß√µes funcionais, c√≥digo limpo
- [x] **Refatora√ß√£o para m√≥dulos**: data_loader fragmentado em file_loaders, data_handler, alerts, file_discovery
- [x] **Compatibilidade Spyder**: Sistema de imports robusto com fallback autom√°tico
- [x] **Fun√ß√µes implementadas**: log_alerta, validar_data_d1, gerar_alerta_nao_d1
- [x] **Auditoria sistem√°tica completa**: 7/7 pools verificados contra escrituras originais
- [x] **Template v2.2**: Reorganizado em 5 se√ß√µes l√≥gicas com instru√ß√µes detalhadas
- [x] **Padroniza√ß√£o de dados**: Formatos decimais corrigidos, dados inventados removidos
- [x] **Monitores customizados identificados**: 20+ monitores espec√≠ficos mapeados
- [x] **Monitor de subordina√ß√£o**: 100% implementado e testado
- [x] **Orquestrador de subordina√ß√£o**: Implementado com logging e alertas
- [x] **Estrat√©gia de tratamento de erros**: Definida por severidade e categoria
- [x] **Monitor de inadimpl√™ncia**: Funcionalmente completo, aguarda integra√ß√£o
- [x] **Arquitetura de enriquecimento**: Estrat√©gia de dados progressivos definida
- [x] **Padr√µes de nomenclatura**: `_find_*_monitor()`, `_has_*_monitoring()`, `run_*_monitoring()`
- [x] **Integra√ß√£o data_loader + orchestrator**: Fluxo centralizado definido

### üîÑ Em Desenvolvimento
- [ ] **Classes de erro espec√≠ficas**: Implementar enum de severidade e classes customizadas
- [ ] **Sistema de retry**: Backoff exponencial para erros tempor√°rios
- [ ] Sistema de descoberta autom√°tica de pools (`pool_discovery.py`)
- [ ] Engine de orquestra√ß√£o (`monitoring_engine.py`)
- [ ] Carregador de configura√ß√µes (`config_loader.py`)
- [ ] Gerenciador de alertas (`alert_manager.py`)
- [ ] Implementa√ß√£o das fun√ß√µes nos utilit√°rios
- [ ] Implementa√ß√£o das fun√ß√µes nos monitores base

### üìã Pr√≥ximos Passos
1. ‚úÖ **Criar pasta data/config/** com ignore_pools.json e test_pools.json
2. ‚úÖ **Implementar data_loader.py** com fluxo refinado de 9 etapas - COMPLETO
3. ‚úÖ **Implementar monitor_subordinacao.py** - COMPLETO
4. ‚úÖ **Implementar orquestrador de subordina√ß√£o** - COMPLETO
5. ‚úÖ **Definir arquitetura de enriquecimento progressivo** - COMPLETO
6. **Implementar orchestrator.run_monitoring()** - Nova fun√ß√£o master integrada
7. **Integrar monitor_inadimplencia.py** com enriquecimento de DataFrame
8. **Implementar fun√ß√µes auxiliares** (`_has_*_monitoring()` para cada monitor)
9. **Implementar monitor_concentracao.py** (2 eventos base)
10. **Implementar monitor_elegibilidade.py** (1 evento base)
11. **Criar supersim_pool_1_recovery_rate.py** (üîß Custom SuperSim)
12. **Criar afa_pool_1_sacados_especificos.py** (üîß Custom AFA)
13. **Criar upvendas_pool_2_substituicao_pix.py** (üîß Custom UpVendas)
14. **Sistema de PDD** (v2.0 - Provis√£o para Devedores Duvidosos)

### üìä M√©tricas de Progresso
- **Pools mapeados**: 7 (lecapital, afa, supersim, credmei, formento, upvendas, a55)
- **Pools com JSON otimizado**: 7/7 (100% - template v2.2 aplicado)
- **Auditoria de dados**: 7/7 pools (100% verificados contra escrituras originais)
- **Integridade de dados**: 100% - Zero dados inventados ou incorretos
- **Estrutura organizada**: ‚úÖ `/base/`, `/custom/`, `/utils/`
- **Monitores base**: 5/5 (esqueletos criados e organizados)
- **Monitores custom**: 0/20+ identificados (recovery_rate, sacados_especificos, veto_aquisicoes, etc.)
- **Utilit√°rios**: 5/5 ‚úÖ (todos refatorados e funcionais)
  - data_loader.py: ‚úÖ Orquestrador principal
  - file_loaders.py: ‚úÖ Carregamento CSV/XLSX
  - data_handler.py: ‚úÖ Valida√ß√µes e metadados
  - alerts.py: ‚úÖ Sistema de alertas
  - file_discovery.py: ‚úÖ Descoberta de arquivos
- **Sistema de descoberta**: 0/4 (pool_discovery, monitoring_engine, config_loader, alert_manager)
- **Fluxo de carregamento**: ‚úÖ COMPLETO - 9 etapas + filtros + ignore list + valida√ß√µes
- **Compatibilidade Spyder**: ‚úÖ COMPLETO - Sistema de imports com fallback
- **Arquivos de configura√ß√£o**: ‚úÖ 2/2 (ignore_pools.json, test_pools.json)
- **Template atualizado**: v2.2 com 5 se√ß√µes l√≥gicas e instru√ß√µes detalhadas
- **Eventos base mapeados**: 7/7 (template v2.2)
- **Eventos base implementados**: 4/7 (subordina√ß√£o + inadimpl√™ncia prontos)
- **Eventos customizados identificados**: 20+ (espec√≠ficos por pool)
- **Monitores base implementados**: 2/5 (subordina√ß√£o ‚úÖ, inadimpl√™ncia ‚úÖ pronto)
- **Monitores customizados implementados**: 0/20+
- **Orquestradores implementados**: 1/1 (arquitetura integrada definida)
- **Estrat√©gia de enriquecimento**: 100% definida (dias_atraso, grupo_de_risco)

## Depend√™ncias Principais
- xlwings: Interface Excel
- pandas: Processamento de dados
- openpyxl: Leitura de XLSX
- json: Configura√ß√µes
- **Spyder**: IDE principal para desenvolvimento e testes

## Ambiente de Desenvolvimento

### Execu√ß√£o no Spyder
O sistema foi desenvolvido e √© testado principalmente no **Spyder IDE**. Para executar o data_loader:

```python
# No console do Spyder, navegue at√© o diret√≥rio do projeto
cd /mnt/c/amfi

# Execute o data_loader
from monitor.utils.data_loader import load_pool_data
resultado = load_pool_data()

# Para debug espec√≠fico de pools
from monitor.utils.data_loader import load_pool_data
resultado = load_pool_data(data="07/07/2025")  # Data espec√≠fica
```

### Compatibilidade de Imports
O c√≥digo foi refatorado para suportar diferentes contextos de execu√ß√£o:
- **Imports relativos**: Para execu√ß√£o como m√≥dulo Python
- **Imports diretos**: Para execu√ß√£o no Spyder (fallback autom√°tico)
- **Imports absolutos**: Para execu√ß√£o em outros ambientes

### Estrutura de Imports Robusta
Todos os arquivos em `monitor/utils/` usam o seguinte padr√£o:
```python
# Tentar imports relativos primeiro
try:
    from .modulo import funcao
except (ImportError, ValueError):
    # Fallback para imports diretos (Spyder)
    if os.path.dirname(__file__) not in sys.path:
        sys.path.insert(0, os.path.dirname(__file__))
    from modulo import funcao
```

## Documenta√ß√£o Dispon√≠vel

### Documenta√ß√£o Principal
- **[CLAUDE.md](./CLAUDE.md)** - Documenta√ß√£o principal do sistema (este arquivo)
- **[PRD.md](./PRD.md)** - Product Requirements Document com objetivos e roadmap

### Processos Operacionais (`docs/processos/`)
- **[PROCESSO_EXTRACAO_SISTEMATICA.md](./processos/PROCESSO_EXTRACAO_SISTEMATICA.md)** - Metodologia para extrair features de documentos legais
- **[CHECKLIST_EXTRACAO_FEATURES.md](./processos/CHECKLIST_EXTRACAO_FEATURES.md)** - Checklist operacional para extra√ß√£o de features

### Documenta√ß√£o T√©cnica (`docs/technical/`)
- **[VALIDACAO_SCHEMA_JSON.md](./technical/VALIDACAO_SCHEMA_JSON.md)** - Diretrizes para valida√ß√£o de schema JSON e compatibilidade Python

## Contato e Sess√µes
- √öltima atualiza√ß√£o: 2025-07-12
- Sess√£o atual: Defini√ß√£o de estrat√©gia de tratamento de erros no orquestrador
- Pr√≥xima revis√£o: Implementa√ß√£o de classes de erro espec√≠ficas e sistema de retry

### üìÅ **Filosofia do docs/sessions/**

**PROP√ìSITO EXCLUSIVO**: Lista de tarefas organizadas por data de sess√£o

**CONTE√öDO PERMITIDO**:
- ‚úÖ To-dos priorizados com checkboxes [ ]
- ‚úÖ Status de progresso (x/y tarefas conclu√≠das)
- ‚úÖ Pr√≥xima tarefa priorit√°ria a executar
- ‚úÖ Ordem de implementa√ß√£o recomendada

**CONTE√öDO ESTRITAMENTE PROIBIDO**:
- ‚ùå Descobertas t√©cnicas ‚Üí docs/SYSTEM_STATE.md
- ‚ùå Defini√ß√µes de arquitetura ‚Üí docs/CLAUDE.md  
- ‚ùå Checklists e processos ‚Üí docs/processos/
- ‚ùå Documenta√ß√£o detalhada ‚Üí docs/technical/
- ‚ùå M√©tricas de performance ‚Üí docs/SYSTEM_STATE.md
- ‚ùå Interfaces e c√≥digo ‚Üí docs/CLAUDE.md
- ‚ùå An√°lises e explica√ß√µes ‚Üí docs/technical/

**FORMATO PADR√ÉO**: Apenas listas estruturadas com prioridades (Alta/M√©dia/Baixa)

### üìã **Sistema de To-Do por Sess√£o**
**TODA NOVA SESS√ÉO** deve seguir este processo:
1. **Criar arquivo**: `docs/sessions/to_do_YYYYMMDD.md`
2. **Listar tarefas**: Incluir tarefas pendentes + novas do dia
3. **Escolher foco**: Selecionar quais tarefas abordar na sess√£o
4. **Adicionar dinamicamente**: Conforme surgem novas demandas
5. **MANTER FOCO**: Apenas to-dos, sem documenta√ß√£o t√©cnica

**Arquivo atual**: [to_do_20250713.md](./sessions/to_do_20250713.md)

### ‚ö†Ô∏è **IMPORTANTE - Sincronia de Documentos**
**SEMPRE VERIFICAR** em cada sess√£o se CLAUDE.md e PRD.md est√£o sincronizados:
- **CLAUDE.md**: Documento principal completo (neg√≥cio + t√©cnico)
- **PRD.md**: Resumo executivo para stakeholders
- **Verificar**: Objetivos, roadmap e m√©tricas alinhados entre os documentos
- **Atualizar**: Ambos documentos quando houver mudan√ßas significativas