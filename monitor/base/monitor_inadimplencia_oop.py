"""
Monitor de Inadimpl√™ncia - Vers√£o Orientada a Objetos
====================================================

Refatora√ß√£o do monitor de inadimpl√™ncia usando arquitetura OOP baseada em BaseMonitor.
Mant√©m 100% compatibilidade com a interface original run_delinquency_monitoring().

Responsabilidades:
- Monitorar inadimpl√™ncia por m√∫ltiplas janelas configur√°veis
- ENRIQUECIMENTO PROGRESSIVO: Adicionar campos ao DataFrame global
- Gerar matriz detalhada de atrasos
- An√°lise de aging configur√°vel com drill-down

Funcionalidade CR√çTICA - Enriquecimento Progressivo:
- Adiciona 'dias_atraso' e 'grupo_de_risco' ao DataFrame carteira_xlsx
- Permite reutiliza√ß√£o por outros monitores (PDD, Concentra√ß√£o)
- Modifica DataFrame IN-PLACE para performance

Melhorias implementadas:
- Heran√ßa de BaseMonitor (elimina redund√¢ncias)
- Valida√ß√£o centralizada
- Resultado padronizado via ResultBuilder
- C√≥digo mais limpo e reutiliz√°vel

Funcionalidades preservadas:
- M√∫ltiplas janelas de inadimpl√™ncia
- Enriquecimento progressivo completo
- Matriz detalhada de atrasos
- Aging analysis configur√°vel
- Todas as valida√ß√µes originais

Autor: AmFi Development Team
Data: 2025-07-17
"""

import sys
import os
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple

# Adicionar path para imports
sys.path.insert(0, '/mnt/c/amfi/monitor')
sys.path.insert(0, '/mnt/c/amfi/monitor/base')

try:
    from .base_monitor import BaseMonitor
except ImportError:
    # Fallback para execu√ß√£o direta
    from base_monitor import BaseMonitor


class DelinquencyMonitor(BaseMonitor):
    """
    Monitor de inadimpl√™ncia usando arquitetura orientada a objetos.
    
    Herda de BaseMonitor e implementa l√≥gica espec√≠fica de inadimpl√™ncia:
    - Enriquecimento progressivo de dados
    - M√∫ltiplas janelas configur√°veis
    - Matriz detalhada de atrasos
    - An√°lise de aging configur√°vel
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Inicializa monitor de inadimpl√™ncia.
        
        Args:
            config: Configura√ß√£o JSON completa do pool
        """
        super().__init__(monitor_id="inadimplencia", config=config)
        self._delinquency_monitors = self._find_delinquency_monitors()
        self._pdd_config = self._find_pdd_config()
        
        # Debug removido - vers√£o final
    
    def is_active(self) -> bool:
        """
        Verifica se o monitor est√° ativo.
        
        Para inadimpl√™ncia, considera ativo se houver pelo menos um monitor ativo.
        
        Returns:
            True se monitor est√° ativo
        """
        return len(self._delinquency_monitors) > 0
    
    def get_required_columns(self) -> List[str]:
        """
        Retorna colunas obrigat√≥rias para inadimpl√™ncia.
        
        Returns:
            Lista de colunas obrigat√≥rias
        """
        return [
            'vencimento_original',
            'valor_presente', 
            'pool',
            'status'
        ]
    
    def validate_data(self, pool_csv: pd.DataFrame, carteira_xlsx: pd.DataFrame) -> bool:
        """
        Valida√ß√£o espec√≠fica para inadimpl√™ncia.
        
        Args:
            pool_csv: DataFrame com dados do pool
            carteira_xlsx: DataFrame com carteira detalhada
            
        Returns:
            True se valida√ß√£o passou
        """
        try:
            # Valida√ß√µes b√°sicas da classe base
            required_columns = self.get_required_columns()
            if not self.validate_basic_data(carteira_xlsx, required_columns):
                return False
            
            # Valida√ß√£o espec√≠fica: pelo menos um monitor de inadimpl√™ncia ativo
            if not self._delinquency_monitors:
                raise ValueError("Nenhum monitor de inadimpl√™ncia ativo encontrado")
            
            # Valida√ß√£o: pool_csv deve ter PL
            if 'pl' not in pool_csv.columns:
                raise ValueError("Coluna 'pl' n√£o encontrada no CSV do pool")
            
            # Valida√ß√£o: vencimento_original deve ser datetime
            if not pd.api.types.is_datetime64_any_dtype(carteira_xlsx['vencimento_original']):
                raise ValueError("Coluna 'vencimento_original' deve ser datetime")
            
            return True
            
        except Exception as e:
            print(f"Erro na valida√ß√£o de inadimpl√™ncia: {e}")
            return False
    
    def calculate(self, pool_csv: pd.DataFrame, carteira_xlsx: pd.DataFrame) -> Dict[str, Any]:
        """
        L√≥gica principal de c√°lculo de inadimpl√™ncia.
        
        Args:
            pool_csv: DataFrame com dados do pool
            carteira_xlsx: DataFrame com carteira detalhada
            
        Returns:
            Dict com resultados completos
        """
        try:
            # 1. ENRIQUECIMENTO PROGRESSIVO (CR√çTICO)
            self._enrich_dataframe_progressively(carteira_xlsx)
            
            # 2. Filtrar dados do pool
            pool_id = self.config.get('pool_id', '')
            pool_xlsx = carteira_xlsx[carteira_xlsx['pool'] == pool_id].copy()
            
            if pool_xlsx.empty:
                raise ValueError(f"Nenhum dado encontrado para pool '{pool_id}'")
            
            # 3. Obter PL do pool
            pl_pool = float(pool_csv['pl'].iloc[0])
            
            # 4. Calcular inadimpl√™ncia por janela
            resultados_janelas = self._calculate_delinquency_windows(pool_xlsx, pl_pool)
            
            # 5. Gerar matriz detalhada de atrasos
            matriz_atrasos = self._generate_detailed_matrix(pool_xlsx)
            
            # 6. Gerar an√°lise de aging
            aging_analysis = self._generate_aging_analysis(pool_xlsx)
            
            # 7. Consolidar resultados
            resultado = {
                "pool_id": pool_id,
                "pl_pool": pl_pool,
                "resultados": resultados_janelas,
                "matriz_atrasos": matriz_atrasos,
                "aging_analysis": aging_analysis,
                "metadata": {
                    "dias_atraso_adicionado": 'dias_atraso' in carteira_xlsx.columns,
                    "grupo_de_risco_adicionado": 'grupo_de_risco' in carteira_xlsx.columns,
                    "registros_pool": len(pool_xlsx),
                    "registros_total_xlsx": len(carteira_xlsx)
                }
            }
            
            return resultado
            
        except Exception as e:
            print(f"Erro no c√°lculo de inadimpl√™ncia: {e}")
            raise
    
    def _enrich_dataframe_progressively(self, carteira_xlsx: pd.DataFrame) -> None:
        """
        FUNCIONALIDADE CR√çTICA: Enriquecimento progressivo do DataFrame.
        
        Adiciona campos calculados ao DataFrame global para reutiliza√ß√£o
        por outros monitores (PDD, Concentra√ß√£o).
        
        Args:
            carteira_xlsx: DataFrame global a ser enriquecido IN-PLACE
        """
        print(f"üîÑ ENRIQUECIMENTO PROGRESSIVO: Iniciando...")
        
        # 1. Adicionar dias_atraso
        if 'dias_atraso' not in carteira_xlsx.columns:
            carteira_xlsx['dias_atraso'] = self._calculate_days_overdue(carteira_xlsx)
            print(f"‚úÖ ENRIQUECIMENTO: Campo 'dias_atraso' adicionado ao XLSX global")
        else:
            print(f"‚ÑπÔ∏è  Campo 'dias_atraso' j√° existe - reutilizando")
        
        # 2. Adicionar grupo_de_risco
        if 'grupo_de_risco' not in carteira_xlsx.columns:
            if self._pdd_config:
                carteira_xlsx['grupo_de_risco'] = self._classify_risk_groups(
                    carteira_xlsx['dias_atraso'], 
                    self._pdd_config
                )
                print(f"‚úÖ ENRIQUECIMENTO: Campo 'grupo_de_risco' adicionado ao XLSX global")
            else:
                print(f"‚ö†Ô∏è Configura√ß√£o PDD n√£o encontrada - grupo_de_risco n√£o adicionado")
        else:
            print(f"‚ÑπÔ∏è  Campo 'grupo_de_risco' j√° existe - reutilizando")
        
        print(f"üéØ ENRIQUECIMENTO PROGRESSIVO: Conclu√≠do com sucesso")
    
    def _calculate_days_overdue(self, xlsx_df: pd.DataFrame, reference_date: Optional[datetime] = None) -> pd.Series:
        """
        Calcula dias de atraso para cada t√≠tulo.
        
        Args:
            xlsx_df: DataFrame com carteira
            reference_date: Data de refer√™ncia (default: hoje)
            
        Returns:
            Series com dias de atraso
        """
        if reference_date is None:
            reference_date = datetime.now()
        
        # Calcular dias de atraso
        dias_atraso = (reference_date - xlsx_df['vencimento_original']).dt.days
        
        # T√≠tulos n√£o vencidos t√™m 0 dias de atraso
        dias_atraso = dias_atraso.clip(lower=0)
        
        return dias_atraso
    
    def _classify_risk_groups(self, dias_atraso: pd.Series, pdd_config: Dict[str, Any]) -> pd.Series:
        """
        Classifica grupos de risco baseado em dias de atraso.
        
        Args:
            dias_atraso: Series com dias de atraso
            pdd_config: Configura√ß√£o PDD (monitor completo)
            
        Returns:
            Series com grupos de risco (AA, A, B, C, D, E, F, G, H)
        """
        # Obter configura√ß√£o PDD diretamente da configura√ß√£o do pool
        grupos_risco = self.config.get('provisoes_pdd', {}).get('grupos_risco', {})
        
        def classificar_grupo(dias):
            for grupo, config_grupo in sorted(grupos_risco.items()):
                if dias <= config_grupo['atraso_max_dias']:
                    return grupo
            return 'H'  # Fallback para pior grupo
        
        return dias_atraso.apply(classificar_grupo)
    
    def _calculate_delinquency_windows(self, pool_xlsx: pd.DataFrame, pl_pool: float) -> Dict[str, Any]:
        """
        Calcula inadimpl√™ncia para m√∫ltiplas janelas usando estrutura original.
        
        Args:
            pool_xlsx: DataFrame filtrado do pool
            pl_pool: Patrim√¥nio l√≠quido do pool
            
        Returns:
            Dict com resultados por janela (formato original)
        """
        resultados = {}
        
        for monitor in self._delinquency_monitors:
            # Extrair configura√ß√£o (seguindo estrutura original)
            window_days = monitor['limites'].get('prazo_dias', 1)
            limite = monitor['limites']['limite']
            
            # Gerar key baseada no prazo ou usar ID do monitor se prazo=1
            if window_days == 1:
                key = monitor.get('id', 'inadimplencia_geral')
            else:
                key = f"inadimplencia_{window_days}d"
            
            # Verificar se h√° t√≠tulos atrasados
            titulos_atrasados = pool_xlsx[pool_xlsx['dias_atraso'] > 0]
            
            if titulos_atrasados.empty:
                resultados[key] = {
                    "percentual": 0.0,
                    "valor_absoluto": 0.0,
                    "pl_base": round(float(pl_pool), 2),
                    "limite": round(limite * 100, 2),
                    "status": "enquadrado",
                    "margem": round(limite * 100, 2),
                    "quantidade_titulos": 0
                }
                continue
            
            # Filtrar por janela (>= window_days)
            titulos_janela = titulos_atrasados[titulos_atrasados['dias_atraso'] >= window_days]
            
            # Calcular valores
            valor_total_atraso = titulos_janela['valor_presente'].sum()
            quantidade_titulos = len(titulos_janela)
            
            # Calcular percentual
            percentual_delinquency = (valor_total_atraso / pl_pool) * 100
            
            # Determinar status
            status = "enquadrado" if percentual_delinquency <= (limite * 100) else "violado"
            
            # Calcular margem
            margem = (limite * 100) - percentual_delinquency
            
            # Resultado no formato original
            resultados[key] = {
                "percentual": round(percentual_delinquency, 2),
                "valor_absoluto": round(float(valor_total_atraso), 2),
                "pl_base": round(float(pl_pool), 2),
                "limite": round(limite * 100, 2),
                "status": status,
                "margem": round(margem, 2),
                "quantidade_titulos": quantidade_titulos
            }
        
        return resultados
    
    def _generate_detailed_matrix(self, pool_xlsx: pd.DataFrame) -> Dict[str, Any]:
        """
        Gera matriz detalhada de atrasos.
        
        Args:
            pool_xlsx: DataFrame filtrado do pool
            
        Returns:
            Dict com matriz completa
        """
        # Filtrar apenas t√≠tulos atrasados
        titulos_atrasados = pool_xlsx[pool_xlsx['dias_atraso'] > 0]
        
        if titulos_atrasados.empty:
            return {
                "lista_titulos_atrasados": [],
                "consolidado_por_cedente": {},
                "consolidado_por_sacado": {},
                "estatisticas_gerais": {
                    "total_titulos_atrasados": 0,
                    "valor_total_em_atraso": 0,
                    "atraso_medio_dias": 0,
                    "quantidade_cedentes_afetados": 0,
                    "quantidade_sacados_afetados": 0
                }
            }
        
        # Lista detalhada de t√≠tulos
        lista_titulos = []
        for _, row in titulos_atrasados.iterrows():
            lista_titulos.append({
                "cedente": row.get('nome_do_cedente', row.get('cedente', 'N/A')),
                "sacado": row.get('nome_do_sacado', row.get('sacado', 'N/A')),
                "valor_presente": float(row['valor_presente']),
                "dias_atraso": int(row['dias_atraso']),
                "data_vencimento": row['vencimento_original'].strftime('%Y-%m-%d'),
                "grupo_de_risco": row.get('grupo_de_risco', 'N/A'),
                "status": row.get('status', 'atrasada'),
                "numero_documento": row.get('numero_documento', 'N/A'),
                "data_emissao": row['data_emissao'].strftime('%Y-%m-%d') if pd.notna(row.get('data_emissao')) else None
            })
        
        # Consolida√ß√£o por cedente
        consolidado_cedente = {}
        cedente_col = 'nome_do_cedente' if 'nome_do_cedente' in titulos_atrasados.columns else 'cedente'
        
        for cedente, grupo in titulos_atrasados.groupby(cedente_col):
            consolidado_cedente[cedente] = {
                "quantidade_titulos": len(grupo),
                "valor_total_atraso": float(grupo['valor_presente'].sum()),
                "maior_atraso_dias": int(grupo['dias_atraso'].max()),
                "distribuicao_faixas": self._calculate_distribution_ranges(grupo['dias_atraso'])
            }
        
        # Consolida√ß√£o por sacado
        consolidado_sacado = {}
        sacado_col = 'nome_do_sacado' if 'nome_do_sacado' in titulos_atrasados.columns else 'sacado'
        
        for sacado, grupo in titulos_atrasados.groupby(sacado_col):
            cedentes_afetados = grupo[cedente_col].unique().tolist()
            consolidado_sacado[sacado] = {
                "quantidade_titulos": len(grupo),
                "valor_total_atraso": float(grupo['valor_presente'].sum()),
                "quantidade_cedentes": len(cedentes_afetados),
                "lista_cedentes": cedentes_afetados
            }
        
        # Estat√≠sticas gerais
        estatisticas = {
            "total_titulos_atrasados": len(titulos_atrasados),
            "valor_total_em_atraso": round(float(titulos_atrasados['valor_presente'].sum()), 2),
            "atraso_medio_dias": round(float(titulos_atrasados['dias_atraso'].mean()), 1),
            "quantidade_cedentes_afetados": len(consolidado_cedente),
            "quantidade_sacados_afetados": len(consolidado_sacado)
        }
        
        return {
            "lista_titulos_atrasados": lista_titulos,
            "consolidado_por_cedente": consolidado_cedente,
            "consolidado_por_sacado": consolidado_sacado,
            "estatisticas_gerais": estatisticas
        }
    
    def _calculate_distribution_ranges(self, dias_atraso: pd.Series) -> Dict[str, int]:
        """
        Calcula distribui√ß√£o por faixas de atraso.
        
        Args:
            dias_atraso: Series com dias de atraso
            
        Returns:
            Dict com contagem por faixa
        """
        faixas = {
            "1-30": 0,
            "31-60": 0,
            "61-90": 0,
            "90+": 0
        }
        
        for dias in dias_atraso:
            if dias <= 30:
                faixas["1-30"] += 1
            elif dias <= 60:
                faixas["31-60"] += 1
            elif dias <= 90:
                faixas["61-90"] += 1
            else:
                faixas["90+"] += 1
        
        return faixas
    
    def _generate_aging_analysis(self, pool_xlsx: pd.DataFrame) -> Dict[str, Any]:
        """
        Gera an√°lise de aging configur√°vel.
        
        Args:
            pool_xlsx: DataFrame filtrado do pool
            
        Returns:
            Dict com an√°lise de aging
        """
        # Extrair faixas de aging da configura√ß√£o PDD
        aging_ranges = self._extract_aging_ranges_from_pdd()
        
        # Agrupar por faixas
        faixas = {}
        pl_pool = float(pool_xlsx['valor_presente'].sum())
        
        for range_name, min_days, max_days in aging_ranges:
            if range_name == "adimplente":
                # T√≠tulos n√£o atrasados (baseado em dias_atraso)
                faixa_data = pool_xlsx[pool_xlsx['dias_atraso'] == 0]
            elif max_days == float('inf'):
                # Faixa final (ex: 181+)
                faixa_data = pool_xlsx[pool_xlsx['dias_atraso'] >= min_days]
            else:
                # Faixa intermedi√°ria
                faixa_data = pool_xlsx[
                    (pool_xlsx['dias_atraso'] >= min_days) & 
                    (pool_xlsx['dias_atraso'] <= max_days)
                ]
            
            valor_total = faixa_data['valor_presente'].sum()
            percentual = (valor_total / pl_pool * 100) if pl_pool > 0 else 0
            
            # Detalhes por ativo (drill-down) - obrigat√≥rio exceto para adimplente
            detalhes_ativos = []
            detalhes_df = pd.DataFrame()
            if range_name != "adimplente" and not faixa_data.empty:
                for _, row in faixa_data.iterrows():
                    detalhes_ativos.append({
                        "cedente": row.get('nome_do_cedente', row.get('cedente', 'N/A')),
                        "sacado": row.get('nome_do_sacado', row.get('sacado', 'N/A')),
                        "valor_presente": float(row['valor_presente']),
                        "dias_atraso": int(row['dias_atraso']),
                        "vencimento": row['vencimento_original'].strftime('%Y-%m-%d')
                    })
                
                # DataFrame ordenado para an√°lise
                detalhes_df = faixa_data.sort_values([
                    'nome_do_cedente' if 'nome_do_cedente' in faixa_data.columns else 'cedente',
                    'vencimento_original',
                    'valor_presente'
                ], ascending=[True, True, False])
            
            faixas[range_name] = {
                "quantidade": len(faixa_data),
                "valor": round(float(valor_total), 2),
                "percentual": round(percentual, 2),
                "detalhes_ativos": detalhes_ativos,
                "detalhes_ativos_df": detalhes_df
            }
        
        return {
            "faixas": faixas,
            "pl_pool": pl_pool,
            "configuracao_utilizada": "PDD" if self._pdd_config else "Padr√£o"
        }
    
    def _extract_aging_ranges_from_pdd(self) -> List[Tuple[str, int, int]]:
        """
        Extrai faixas de aging da configura√ß√£o PDD (compat√≠vel com original).
        
        Returns:
            Lista de tuplas (nome_faixa, min_dias, max_dias)
        """
        # Obter configura√ß√£o PDD diretamente da configura√ß√£o do pool
        pdd_config = self.config.get('provisoes_pdd', {}).get('grupos_risco', {})
        
        if not pdd_config:
            # Faixas padr√£o se n√£o houver configura√ß√£o PDD
            return [
                ("adimplente", 0, 0),
                ("1-30", 1, 30),
                ("31-60", 31, 60),
                ("61-90", 61, 90),
                ("90+", 91, float('inf'))
            ]
        
        # Converter grupos PDD em faixas de aging (usando mesma l√≥gica que o original)
        faixas = []
        grupos_ordenados = sorted(pdd_config.items(), key=lambda x: x[1]['atraso_max_dias'])
        
        # Primeira faixa: adimplente (0 dias)
        faixas.append(("adimplente", 0, 0))
        
        # Faixas baseadas nos grupos de risco
        prev_max = 0
        for grupo, config_grupo in grupos_ordenados:
            max_dias = config_grupo['atraso_max_dias']
            
            if max_dias > prev_max:
                min_dias = prev_max + 1
                
                # Tratamento especial para √∫ltimo grupo (999 dias = infinito)
                if max_dias >= 999:
                    label = f"{min_dias}+"
                    faixas.append((label, min_dias, float('inf')))
                else:
                    if min_dias == max_dias:
                        label = f"{min_dias}d"
                    else:
                        label = f"{min_dias}-{max_dias}"
                    faixas.append((label, min_dias, max_dias))
                
                prev_max = max_dias
        
        return faixas
    
    def _find_delinquency_monitors(self) -> List[Dict[str, Any]]:
        """
        Busca monitores de inadimpl√™ncia na configura√ß√£o.
        
        Returns:
            Lista de monitores encontrados
        """
        monitors = []
        
        monitoramentos = self.config.get('monitoramentos_ativos', [])
        for monitor in monitoramentos:
            # Buscar por ID que cont√©m 'inadimplencia' ou tipo 'inadimplencia'
            monitor_id = monitor.get('id', '')
            monitor_tipo = monitor.get('tipo', '')
            
            if 'inadimplencia' in monitor_id or monitor_tipo == 'inadimplencia':
                if monitor.get('ativo', False):  # Apenas ativos
                    monitors.append(monitor)
        
        return monitors
    
    def _find_pdd_config(self) -> Optional[Dict[str, Any]]:
        """
        Busca configura√ß√£o PDD para classifica√ß√£o de grupos.
        
        Returns:
            Configura√ß√£o PDD ou None
        """
        # Verificar se h√° configura√ß√£o PDD diretamente na configura√ß√£o do pool
        pdd_config = self.config.get('provisoes_pdd', {}).get('grupos_risco', {})
        
        if pdd_config:
            return {'grupos_risco': pdd_config}
        
        # Fallback: buscar monitor PDD ativo
        monitoramentos = self.config.get('monitoramentos_ativos', [])
        
        for monitor in monitoramentos:
            if monitor.get('id') == 'pdd':
                return monitor
        
        return None
    
    def run_monitoring(self, pool_csv: pd.DataFrame, carteira_xlsx: pd.DataFrame) -> Dict[str, Any]:
        """
        Interface principal do monitor.
        
        Args:
            pool_csv: DataFrame com dados do pool
            carteira_xlsx: DataFrame com carteira detalhada
            
        Returns:
            Dict com resultado completo (formato original)
        """
        try:
            # Validar dados
            if not self.validate_data(pool_csv, carteira_xlsx):
                return {
                    "sucesso": False,
                    "monitor": "inadimplencia",
                    "erro": "Falha na valida√ß√£o de dados"
                }
            
            # Calcular inadimpl√™ncia
            resultado_calculo = self.calculate(pool_csv, carteira_xlsx)
            
            # Construir resultado no formato original
            resultado_final = {
                "sucesso": True,
                "monitor": "inadimplencia",
                "pool_id": resultado_calculo['pool_id'],
                "data_analise": datetime.now().isoformat(),
                "pl_pool": resultado_calculo['pl_pool'],
                "enriquecimento": {
                    "dias_atraso_adicionado": resultado_calculo['metadata']['dias_atraso_adicionado'],
                    "grupo_de_risco_adicionado": resultado_calculo['metadata']['grupo_de_risco_adicionado'],
                    "registros_pool": resultado_calculo['metadata']['registros_pool'],
                    "registros_total_xlsx": resultado_calculo['metadata']['registros_total_xlsx']
                },
                "aging_analysis": resultado_calculo['aging_analysis'],
                "matriz_atrasos": resultado_calculo['matriz_atrasos']
            }
            
            # Adicionar resultados por janela diretamente no n√≠vel raiz
            for janela_key, janela_result in resultado_calculo['resultados'].items():
                resultado_final[janela_key] = janela_result
            
            return resultado_final
            
        except Exception as e:
            return {
                "sucesso": False,
                "monitor": "inadimplencia",
                "erro": str(e),
                "tipo_erro": type(e).__name__
            }


# Fun√ß√£o de compatibilidade com interface original
def run_delinquency_monitoring(
    pool_data_csv: pd.DataFrame,
    carteira_xlsx: pd.DataFrame,
    config: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Interface de compatibilidade com sistema original.
    
    CR√çTICO: Mant√©m funcionalidade de enriquecimento progressivo.
    
    Args:
        pool_data_csv: DataFrame com dados do pool
        carteira_xlsx: DataFrame com carteira detalhada (ser√° enriquecido)
        config: Configura√ß√£o JSON do pool
        
    Returns:
        Dict com resultado completo
    """
    monitor = DelinquencyMonitor(config)
    return monitor.run_monitoring(pool_data_csv, carteira_xlsx)